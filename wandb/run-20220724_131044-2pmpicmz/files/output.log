INFO: Starting training:
        Epochs:          5
        Batch size:      2
        Learning rate:   2e-05
        Training size:   9001
        Validation size: 1000
        Checkpoints:     True
        Device:          cuda
        Images scaling:  1.0
        Mixed Precision: False
Epoch 1/5:   0%|                                      | 0/9001 [00:00<?, ?img/s]/root/miniconda3/envs/acnet/lib/python3.8/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/root/autodl-tmp/acnet/train.py:134: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  true_masks = true_masks // 255.0


Epoch 1/5:   1%|        | 120/9001 [00:09<11:59, 12.35img/s, loss (batch)=0.515]
INFO: Saved interrupt
Traceback (most recent call last):
  File "/root/autodl-tmp/acnet/train.py", line 232, in <module>
    train_net(net=net,
  File "/root/autodl-tmp/acnet/train.py", line 146, in train_net
    optimizer.step()
  File "/root/miniconda3/envs/acnet/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/acnet/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/acnet/lib/python3.8/site-packages/torch/optim/rmsprop.py", line 141, in step
    rmsprop(params_with_grad,
  File "/root/miniconda3/envs/acnet/lib/python3.8/site-packages/torch/optim/rmsprop.py", line 188, in rmsprop
    func(params,
  File "/root/miniconda3/envs/acnet/lib/python3.8/site-packages/torch/optim/rmsprop.py", line 219, in _single_tensor_rmsprop
    grad = grad.add(param, alpha=weight_decay)
KeyboardInterrupt